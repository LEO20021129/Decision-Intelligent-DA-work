{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84240ca5-a661-4c4a-9c2f-0562f28db107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 08:01:59 - INFO - ➡️ Using Windows Integrated Authentication (Trusted_Connection=yes).\n",
      "2025-06-02 08:01:59 - INFO - ✔ Connected to database 'Sepidar01'. Server version: Microsoft SQL Server 2022 (RTM-GDR) (KB5046861) - 16.0.1135.2 (X64) \n",
      "2025-06-02 08:01:59 - INFO - ➡️ Extracting 'GNR.[Party]' …\n",
      "2025-06-02 08:01:59 - INFO - ➡️ Extracting 'SLS.[Invoice]' …\n",
      "2025-06-02 08:01:59 - INFO - ➡️ Extracting 'SLS.[InvoiceItem]' …\n",
      "2025-06-02 08:01:59 - INFO - ➡️ Extracting 'INV.[Item]' …\n",
      "2025-06-02 08:01:59 - INFO - ➡️ Extracting 'PAY.[Personnel]' …\n",
      "2025-06-02 08:01:59 - INFO - ➡️ Extracting 'INV.[ItemStock]' …\n",
      "2025-06-02 08:01:59 - INFO - ➡️ Extracting 'RPA.[ReceiptHeader]' …\n",
      "2025-06-02 08:01:59 - INFO - ✔ Successfully extracted all seven tables from Sepidar01.\n",
      "2025-06-02 08:01:59 - INFO - ✔ SalesFact transformation complete (rows = 308).\n",
      "2025-06-02 08:01:59 - INFO - ➡️ Loading SalesFact into dbo.SalesFact (if_exists='replace')…\n",
      "2025-06-02 08:02:00 - INFO - ✔ dbo.SalesFact loaded (rows = 308).\n",
      "2025-06-02 08:02:02 - INFO - ✔ Saved snapshot: Customer.csv / Customer.parquet\n",
      "2025-06-02 08:02:02 - INFO - ✔ Saved snapshot: Invoice.csv / Invoice.parquet\n",
      "2025-06-02 08:02:02 - INFO - ✔ Saved snapshot: Invoiceitem.csv / Invoiceitem.parquet\n",
      "2025-06-02 08:02:02 - INFO - ✔ Saved snapshot: Product.csv / Product.parquet\n",
      "2025-06-02 08:02:02 - INFO - ✔ Saved snapshot: Employee.csv / Employee.parquet\n",
      "2025-06-02 08:02:02 - INFO - ✔ Saved snapshot: Inventory.csv / Inventory.parquet\n",
      "2025-06-02 08:02:02 - INFO - ✔ Saved snapshot: Payment.csv / Payment.parquet\n",
      "2025-06-02 08:02:02 - INFO - ✔ Saved SalesFact_snapshot.csv / SalesFact_snapshot.parquet\n",
      "2025-06-02 08:02:02 - INFO - 🎉 === ETL PIPELINE FOR Sepidar01 COMPLETED SUCCESSFULLY ===\n",
      "2025-06-02 08:02:02 - INFO - Disposed SQLAlchemy engine.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# STEP 0: USER CONFIGURATION — point at your Sepidar01 database\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "SQL_SERVER_HOST     = \"WENLINHNBB\"   # ← e.g. \"localhost\\\\SQLEXPRESS\"\n",
    "SQL_SERVER_PORT     = 1433           # ← usually 1433\n",
    "SQL_SERVER_DATABASE = \"Sepidar01\"    # ← your database name\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def get_sqlalchemy_engine():\n",
    "    # Create a SQLAlchemy engine using Windows Integrated Authentication.\n",
    "    if SQL_SERVER_HOST in (\"\", \"YOUR_SQL_SERVER_HOST_HERE\"):\n",
    "        raise ValueError(\"Please set SQL_SERVER_HOST to your actual server/instance.\")\n",
    "    if SQL_SERVER_DATABASE in (\"\", \"YOUR_DATABASE_NAME_HERE\"):\n",
    "        raise ValueError(\"Please set SQL_SERVER_DATABASE to your actual database name.\")\n",
    "\n",
    "    driver_params = {\n",
    "        \"driver\": \"ODBC Driver 17 for SQL Server\",\n",
    "        \"Trusted_Connection\": \"yes\"\n",
    "    }\n",
    "    logger.info(\"➡️ Using Windows Integrated Authentication (Trusted_Connection=yes).\")\n",
    "\n",
    "    connection_url = URL.create(\n",
    "        \"mssql+pyodbc\",\n",
    "        username=None,\n",
    "        password=None,\n",
    "        host=SQL_SERVER_HOST,\n",
    "        port=int(SQL_SERVER_PORT),\n",
    "        database=SQL_SERVER_DATABASE,\n",
    "        query=driver_params,\n",
    "    )\n",
    "    try:\n",
    "        engine = create_engine(connection_url, fast_executemany=True, echo=False)\n",
    "        with engine.connect() as conn:\n",
    "            version = conn.execute(text(\"SELECT @@VERSION\")).scalar()\n",
    "            logger.info(f\"✔ Connected to database '{SQL_SERVER_DATABASE}'. \"\n",
    "                        f\"Server version: {version.splitlines()[0]}\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        raise ConnectionError(f\"❌ Could not create SQLAlchemy engine: {e}\")\n",
    "\n",
    "\n",
    "def extract_all_tables(engine):\n",
    "    # Extract these seven tables from Sepidar01:\n",
    "    #   • GNR.Party\n",
    "    #   • SLS.Invoice\n",
    "    #   • SLS.InvoiceItem\n",
    "    #   • INV.Item\n",
    "    #   • PAY.Personnel\n",
    "    #   • INV.ItemStock\n",
    "    #   • RPA.ReceiptHeader\n",
    "    table_map = {\n",
    "        \"customer\":    (\"GNR\", \"Party\"),\n",
    "        \"invoice\":     (\"SLS\", \"Invoice\"),\n",
    "        \"invoiceitem\": (\"SLS\", \"InvoiceItem\"),\n",
    "        \"product\":     (\"INV\", \"Item\"),\n",
    "        \"employee\":    (\"PAY\", \"Personnel\"),\n",
    "        \"inventory\":   (\"INV\", \"ItemStock\"),\n",
    "        \"payment\":     (\"RPA\", \"ReceiptHeader\")\n",
    "    }\n",
    "\n",
    "    dfs = {}\n",
    "    for key, (schema, tbl) in table_map.items():\n",
    "        fq_name = f\"{schema}.[{tbl}]\"\n",
    "        logger.info(f\"➡️ Extracting '{fq_name}' …\")\n",
    "        try:\n",
    "            dfs[key] = pd.read_sql(f\"SELECT * FROM {fq_name}\", engine)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"❌ Failed to extract {fq_name}: {e}\")\n",
    "    logger.info(\"✔ Successfully extracted all seven tables from Sepidar01.\")\n",
    "    return dfs\n",
    "\n",
    "\n",
    "def transform_sales_fact(dfs):\n",
    "    # Build “SalesFact” by joining:\n",
    "    #   SLS.InvoiceItem → SLS.Invoice → GNR.Party  ← INV.Item\n",
    "    #\n",
    "    # We pre‑rename any overlapping columns to avoid suffix collisions.\n",
    "\n",
    "    # Aliases\n",
    "    cust_df  = dfs[\"customer\"]     # GNR.Party\n",
    "    inv_df   = dfs[\"invoice\"]      # SLS.Invoice\n",
    "    items_df = dfs[\"invoiceitem\"]  # SLS.InvoiceItem\n",
    "    prod_df  = dfs[\"product\"]      # INV.Item\n",
    "\n",
    "    # 1) Pre‑rename overlapping columns in InvoiceItem → item_df2\n",
    "    item_df2 = items_df.rename(columns={\n",
    "        \"Price\":                   \"LinePrice\",\n",
    "        \"PriceInBaseCurrency\":     \"LinePriceInBase\",\n",
    "        \"Discount\":                \"LineDiscount\",\n",
    "        \"DiscountInBaseCurrency\":  \"LineDiscountInBase\",\n",
    "        \"Addition\":                \"LineAddition\",\n",
    "        \"AdditionInBaseCurrency\":  \"LineAdditionInBase\",\n",
    "        \"Tax\":                     \"LineTax\",\n",
    "        \"TaxInBaseCurrency\":       \"LineTaxInBase\",\n",
    "        \"Duty\":                    \"LineDuty\",\n",
    "        \"DutyInBaseCurrency\":      \"LineDutyInBase\",\n",
    "        \"NetPriceInBaseCurrency\":  \"LineNetInBase\"\n",
    "    })\n",
    "\n",
    "    # 2) Pre‑rename invoice‑level columns in inv_df → inv_subset\n",
    "    inv_subset = inv_df[[\n",
    "        \"InvoiceId\",                 \n",
    "        \"CustomerPartyRef\",\n",
    "        \"Number\",\n",
    "        \"Date\",\n",
    "        \"Price\",\n",
    "        \"PriceInBaseCurrency\",\n",
    "        \"Discount\",\n",
    "        \"DiscountInBaseCurrency\",\n",
    "        \"Addition\",\n",
    "        \"AdditionInBaseCurrency\",\n",
    "        \"Tax\",\n",
    "        \"TaxInBaseCurrency\",\n",
    "        \"Duty\",\n",
    "        \"DutyInBaseCurrency\",\n",
    "        \"NetPriceInBaseCurrency\"\n",
    "    ]].rename(columns={\n",
    "        \"Number\":                 \"InvoiceNumber\",\n",
    "        \"Price\":                  \"InvoicePrice\",\n",
    "        \"PriceInBaseCurrency\":    \"InvoicePriceInBase\",\n",
    "        \"Discount\":               \"InvoiceDiscount\",\n",
    "        \"DiscountInBaseCurrency\": \"InvoiceDiscountInBase\",\n",
    "        \"Addition\":               \"InvoiceAddition\",\n",
    "        \"AdditionInBaseCurrency\": \"InvoiceAdditionInBase\",\n",
    "        \"Tax\":                    \"InvoiceTax\",\n",
    "        \"TaxInBaseCurrency\":      \"InvoiceTaxInBase\",\n",
    "        \"Duty\":                   \"InvoiceDuty\",\n",
    "        \"DutyInBaseCurrency\":     \"InvoiceDutyInBase\",\n",
    "        \"NetPriceInBaseCurrency\": \"InvoiceNetInBase\"\n",
    "    })\n",
    "\n",
    "    # 3) Merge InvoiceItem → Invoice on InvoiceRef = InvoiceId\n",
    "    merged = item_df2.merge(\n",
    "        inv_subset,\n",
    "        how=\"left\",\n",
    "        left_on=\"InvoiceRef\",\n",
    "        right_on=\"InvoiceId\",\n",
    "        validate=\"many_to_one\"\n",
    "    )\n",
    "\n",
    "    # 4) Pre‑rename customer columns into cust_subset\n",
    "    # (GNR.Party does not have “Number” so we drop it here)\n",
    "    cust_subset = cust_df[[\n",
    "        \"PartyId\",        \n",
    "        \"Name\",\n",
    "        \"LastName\",\n",
    "        \"IsCustomer\"\n",
    "    ]].rename(columns={\n",
    "        \"Name\":         \"CustomerFirstName\",\n",
    "        \"LastName\":     \"CustomerLastName\",\n",
    "        \"IsCustomer\":   \"CustomerFlag\"\n",
    "    })\n",
    "\n",
    "    # 5) Merge in Customer on CustomerPartyRef = PartyId\n",
    "    merged = merged.merge(\n",
    "        cust_subset,\n",
    "        how=\"left\",\n",
    "        left_on=\"CustomerPartyRef\",\n",
    "        right_on=\"PartyId\",\n",
    "        validate=\"many_to_one\"\n",
    "    )\n",
    "\n",
    "    # 6) Pre‑rename product columns into prod_subset\n",
    "    prod_subset = prod_df[[\n",
    "        \"ItemID\",            \n",
    "        \"Code\",\n",
    "        \"Title\",\n",
    "        \"UnitRef\",\n",
    "        \"SecondaryUnitRef\",\n",
    "        \"SaleUnitRef\"\n",
    "    ]].rename(columns={\n",
    "        \"Code\":         \"ProductCode\",\n",
    "        \"Title\":        \"ProductTitle\"\n",
    "    })\n",
    "\n",
    "    # 7) Merge in Product on ItemRef = ItemID\n",
    "    merged = merged.merge(\n",
    "        prod_subset,\n",
    "        how=\"left\",\n",
    "        left_on=\"ItemRef\",\n",
    "        right_on=\"ItemID\",\n",
    "        validate=\"many_to_one\"\n",
    "    )\n",
    "\n",
    "    # 8) Final SalesFact DataFrame is “merged”\n",
    "    salesfact = merged.copy()\n",
    "\n",
    "    # 9) Coerce numeric columns to numeric dtype if they exist\n",
    "    numeric_cols = [\n",
    "        \"Quantity\",              \n",
    "        \"LinePrice\",\n",
    "        \"LinePriceInBase\",\n",
    "        \"LineDiscount\",\n",
    "        \"LineDiscountInBase\",\n",
    "        \"LineAddition\",\n",
    "        \"LineAdditionInBase\",\n",
    "        \"LineTax\",\n",
    "        \"LineTaxInBase\",\n",
    "        \"LineDuty\",\n",
    "        \"LineDutyInBase\",\n",
    "        \"LineNetInBase\",\n",
    "        \"InvoicePrice\",\n",
    "        \"InvoicePriceInBase\",\n",
    "        \"InvoiceDiscount\",\n",
    "        \"InvoiceDiscountInBase\",\n",
    "        \"InvoiceAddition\",\n",
    "        \"InvoiceAdditionInBase\",\n",
    "        \"InvoiceTax\",\n",
    "        \"InvoiceTaxInBase\",\n",
    "        \"InvoiceDuty\",\n",
    "        \"InvoiceDutyInBase\",\n",
    "        \"InvoiceNetInBase\"\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        if col in salesfact.columns:\n",
    "            salesfact[col] = pd.to_numeric(salesfact[col], errors=\"coerce\")\n",
    "\n",
    "    logger.info(f\"✔ SalesFact transformation complete (rows = {len(salesfact):,}).\")\n",
    "    return salesfact\n",
    "\n",
    "\n",
    "def load_salesfact_to_sql(df, engine):\n",
    "    # Write the SalesFact DataFrame into Sepidar01.dbo.SalesFact (replace if exists).\n",
    "    # We remove method=\"multi\" to avoid the double‑parenthesis syntax error.\n",
    "    try:\n",
    "        logger.info(\"➡️ Loading SalesFact into dbo.SalesFact (if_exists='replace')…\")\n",
    "        df.to_sql(\n",
    "            name=\"SalesFact\",\n",
    "            schema=\"dbo\",\n",
    "            con=engine,\n",
    "            if_exists=\"replace\",\n",
    "            index=False\n",
    "        )\n",
    "        logger.info(f\"✔ dbo.SalesFact loaded (rows = {len(df):,}).\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"❌ Failed to load dbo.SalesFact: {e}\")\n",
    "\n",
    "\n",
    "def save_all_snapshots(dfs, salesfact_df):\n",
    "    # Save each of the seven raw tables plus SalesFact as CSV & Parquet in the working directory.\n",
    "    try:\n",
    "        for key, df in dfs.items():\n",
    "            name = key[0].upper() + key[1:]  # e.g. “Customer”, “InvoiceItem”\n",
    "            df.to_csv(f\"{name}.csv\", index=False)\n",
    "            df.to_parquet(f\"{name}.parquet\", index=False)\n",
    "            logger.info(f\"✔ Saved snapshot: {name}.csv / {name}.parquet\")\n",
    "\n",
    "        salesfact_df.to_csv(\"SalesFact_snapshot.csv\", index=False)\n",
    "        salesfact_df.to_parquet(\"SalesFact_snapshot.parquet\", index=False)\n",
    "        logger.info(\"✔ Saved SalesFact_snapshot.csv / SalesFact_snapshot.parquet\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"❌ Failed to save snapshots: {e}\")\n",
    "\n",
    "\n",
    "def run_full_etl():\n",
    "    engine = None\n",
    "    try:\n",
    "        engine = get_sqlalchemy_engine()\n",
    "        dfs = extract_all_tables(engine)\n",
    "        salesfact_df = transform_sales_fact(dfs)\n",
    "        load_salesfact_to_sql(salesfact_df, engine)\n",
    "        save_all_snapshots(dfs, salesfact_df)\n",
    "        logger.info(\"🎉 === ETL PIPELINE FOR Sepidar01 COMPLETED SUCCESSFULLY ===\")\n",
    "    except Exception as exc:\n",
    "        logger.error(f\"✘ ETL aborted due to exception:\\n{exc}\")\n",
    "    finally:\n",
    "        if engine is not None:\n",
    "            try:\n",
    "                engine.dispose()\n",
    "                logger.info(\"Disposed SQLAlchemy engine.\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# Execute the ETL pipeline\n",
    "run_full_etl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d0e00-156e-4e53-9181-5041d273b56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
